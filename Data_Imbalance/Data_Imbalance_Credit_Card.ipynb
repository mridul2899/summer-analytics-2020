{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up default plotting parameters\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20.0, 7.0]\n",
    "plt.rcParams.update({'font.size': 22,})\n",
    "\n",
    "sns.set_palette('viridis')\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk', font_scale=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../creditcard.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.Class.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using seaborn countplot to show distribution of questions in dataset\n",
    "fig, ax = plt.subplots()\n",
    "g = sns.countplot(df.Class, palette='viridis')\n",
    "g.set_xticklabels(['Not Fraud', 'Fraud'])\n",
    "g.set_yticklabels([])\n",
    "\n",
    "# function to show values on bars\n",
    "def show_values_on_bars(axs):\n",
    "    def _show_on_single_plot(ax):\n",
    "        for p in ax.patches:\n",
    "            _x = p.get_x() + p.get_width() / 2\n",
    "            _y = p.get_y() + p.get_height()\n",
    "            value = '{:.0f}'.format(p.get_height())\n",
    "            ax.text(_x, _y, value, ha='center')\n",
    "    \n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_single_plot(ax)\n",
    "    else:\n",
    "        _show_on_single_plot(axs)\n",
    "show_values_on_bars(ax)\n",
    "\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title('Distribution of Transactions', fontsize=30)\n",
    "plt.tick_params(axis='x', which='major', labelsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17304750013189596"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print percentage of questions where target == 1\n",
    "(len(df.loc[df.Class == 1])) / (len(df.loc[df.Class == 0])) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have here a very imbalanced dataset, with just .17% data of class 1 and the rest belonging to class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "# Separate input features and target\n",
    "y = df.Class\n",
    "X = df.drop('Class', axis=1)\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted labels: [0]\n",
      "Test score: 0.9981461194910255\n"
     ]
    }
   ],
   "source": [
    "# DummyClassifier to predict only target 0\n",
    "dummy = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "dummy_pred = dummy.predict(X_test)\n",
    "\n",
    "# checking unique labels\n",
    "print('Unique predicted labels:', (np.unique(dummy_pred)))\n",
    "\n",
    "# checking accuracy\n",
    "print('Test score:', accuracy_score(y_test, dummy_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a dummy classifier which only predicts 0 for all the cases is able to achieve an accuracy of more than 99.8%. This is because of data imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling the data as is\n",
    "# Train model\n",
    "lr = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "\n",
    "# Predict on testing set\n",
    "lr_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992135052386169"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking accuracy\n",
    "accuracy_score(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    71108\n",
       "1       94\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking unique values\n",
    "predictions = pd.DataFrame(lr_pred)\n",
    "predictions[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that Logistic Regression performed better than the dummy classifier, as it was also able to predict some 1's. Can we do better? <br>\n",
    "Accuracy isn't the best criteria as we would like to identify maximum number of fraudulent cases possible. <br>\n",
    "Hence, F1 score will be a better criterion since it takes into account precision and recall which deal with true positives, false positives and false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7522123893805309"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score\n",
    "f1_score(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71061</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1\n",
       "0  71061   9\n",
       "1     47  85"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6439393939393939"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we achieved a very high accuracy, our F1 score and recall score metrics are not good. Hence, we need to change our decision algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999592708069998"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "rfc = RandomForestClassifier(n_estimators=10).fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, rfc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8786610878661087"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score\n",
    "f1_score(y_test, rfc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71068</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  71068    2\n",
       "1     27  105"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7954545454545454"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall score\n",
    "recall_score(y_test, rfc_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall now see resampling techniques for making our data lesser imbalanced. <br>\n",
    "Resampling should only be done after splitting training and testing data, otherwise our training and testing data might have same data points; which may cause failure in detecting overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input features and target\n",
    "y = df.Class\n",
    "X = df.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264873</th>\n",
       "      <td>161634.0</td>\n",
       "      <td>-0.395578</td>\n",
       "      <td>1.489129</td>\n",
       "      <td>-0.833442</td>\n",
       "      <td>-0.224271</td>\n",
       "      <td>0.369444</td>\n",
       "      <td>-1.453886</td>\n",
       "      <td>0.796593</td>\n",
       "      <td>-0.060403</td>\n",
       "      <td>0.338270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231624</td>\n",
       "      <td>0.955194</td>\n",
       "      <td>-0.172092</td>\n",
       "      <td>-0.041050</td>\n",
       "      <td>-0.313444</td>\n",
       "      <td>-0.174301</td>\n",
       "      <td>0.064657</td>\n",
       "      <td>-0.036960</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163821</th>\n",
       "      <td>116237.0</td>\n",
       "      <td>1.950487</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>-1.761814</td>\n",
       "      <td>1.232470</td>\n",
       "      <td>0.523175</td>\n",
       "      <td>-0.650657</td>\n",
       "      <td>0.504231</td>\n",
       "      <td>-0.200857</td>\n",
       "      <td>0.116805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086306</td>\n",
       "      <td>0.326297</td>\n",
       "      <td>-0.068839</td>\n",
       "      <td>-0.416589</td>\n",
       "      <td>0.426044</td>\n",
       "      <td>-0.486299</td>\n",
       "      <td>-0.031266</td>\n",
       "      <td>-0.072543</td>\n",
       "      <td>38.44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72083</th>\n",
       "      <td>54557.0</td>\n",
       "      <td>1.105167</td>\n",
       "      <td>-0.166253</td>\n",
       "      <td>0.569520</td>\n",
       "      <td>0.681043</td>\n",
       "      <td>-0.259189</td>\n",
       "      <td>0.642792</td>\n",
       "      <td>-0.437034</td>\n",
       "      <td>0.356746</td>\n",
       "      <td>0.441417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009073</td>\n",
       "      <td>0.293023</td>\n",
       "      <td>-0.028688</td>\n",
       "      <td>-0.242206</td>\n",
       "      <td>0.389813</td>\n",
       "      <td>0.482852</td>\n",
       "      <td>0.010705</td>\n",
       "      <td>-0.008399</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196949</th>\n",
       "      <td>131771.0</td>\n",
       "      <td>1.805238</td>\n",
       "      <td>0.961264</td>\n",
       "      <td>-1.717212</td>\n",
       "      <td>4.094625</td>\n",
       "      <td>0.938666</td>\n",
       "      <td>-0.227785</td>\n",
       "      <td>0.152911</td>\n",
       "      <td>0.066753</td>\n",
       "      <td>-1.073784</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137875</td>\n",
       "      <td>-0.450959</td>\n",
       "      <td>0.098530</td>\n",
       "      <td>-0.662272</td>\n",
       "      <td>-0.150154</td>\n",
       "      <td>-0.098852</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.017622</td>\n",
       "      <td>37.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126213</th>\n",
       "      <td>77959.0</td>\n",
       "      <td>0.835421</td>\n",
       "      <td>-1.191847</td>\n",
       "      <td>0.578455</td>\n",
       "      <td>0.586101</td>\n",
       "      <td>-1.236663</td>\n",
       "      <td>0.194617</td>\n",
       "      <td>-0.532404</td>\n",
       "      <td>0.061561</td>\n",
       "      <td>-0.734344</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072349</td>\n",
       "      <td>-0.109154</td>\n",
       "      <td>-0.308356</td>\n",
       "      <td>0.011968</td>\n",
       "      <td>0.461350</td>\n",
       "      <td>-0.244810</td>\n",
       "      <td>0.031845</td>\n",
       "      <td>0.060910</td>\n",
       "      <td>237.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "264873  161634.0 -0.395578  1.489129 -0.833442 -0.224271  0.369444 -1.453886   \n",
       "163821  116237.0  1.950487  0.002312 -1.761814  1.232470  0.523175 -0.650657   \n",
       "72083    54557.0  1.105167 -0.166253  0.569520  0.681043 -0.259189  0.642792   \n",
       "196949  131771.0  1.805238  0.961264 -1.717212  4.094625  0.938666 -0.227785   \n",
       "126213   77959.0  0.835421 -1.191847  0.578455  0.586101 -1.236663  0.194617   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "264873  0.796593 -0.060403  0.338270  ...  0.231624  0.955194 -0.172092   \n",
       "163821  0.504231 -0.200857  0.116805  ...  0.086306  0.326297 -0.068839   \n",
       "72083  -0.437034  0.356746  0.441417  ...  0.009073  0.293023 -0.028688   \n",
       "196949  0.152911  0.066753 -1.073784  ... -0.137875 -0.450959  0.098530   \n",
       "126213 -0.532404  0.061561 -0.734344  ... -0.072349 -0.109154 -0.308356   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "264873 -0.041050 -0.313444 -0.174301  0.064657 -0.036960    2.74      0  \n",
       "163821 -0.416589  0.426044 -0.486299 -0.031266 -0.072543   38.44      0  \n",
       "72083  -0.242206  0.389813  0.482852  0.010705 -0.008399    1.00      0  \n",
       "196949 -0.662272 -0.150154 -0.098852 -0.000030  0.017622   37.89      0  \n",
       "126213  0.011968  0.461350 -0.244810  0.031845  0.060910  237.00      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate our training data back together\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    213245\n",
       "0    213245\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate minority and majority classes\n",
    "not_fraud = X[X.Class == 0]\n",
    "fraud = X[X.Class == 1]\n",
    "\n",
    "# upsample minority\n",
    "fraud_upsampled = resample(fraud,\n",
    "                           replace=True, # sample with replacement\n",
    "                           n_samples = len(not_fraud), # match number in majority class\n",
    "                           random_state=27) # reproducible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
    "\n",
    "# check new class counts\n",
    "upsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying logistic regression again with the balanced dataset\n",
    "y_train = upsampled.Class\n",
    "X_train = upsampled.drop('Class', axis=1)\n",
    "\n",
    "upsampled = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "\n",
    "upsampled_pred = upsampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9807589674447347"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking accuracy\n",
    "accuracy_score(y_test, upsampled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14375000000000002"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score\n",
    "f1_score(y_test, upsampled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69717</td>\n",
       "      <td>1353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1\n",
       "0  69717  1353\n",
       "1     17   115"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, upsampled_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8712121212121212"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, upsampled_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy decreased after upsampling but the model is now predicting both classes more equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    360\n",
       "0    360\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undersampling majority class\n",
    "# still using separated classes fraud and not_fraud from above\n",
    "\n",
    "# downsample majority\n",
    "not_fraud_downsampled = resample(not_fraud,\n",
    "                                 replace = False, # sample without replacement\n",
    "                                 n_samples = len(fraud), # match minority n\n",
    "                                 random_state = 27) # reproducible results\n",
    "\n",
    "# combine minority and downsampled majority\n",
    "downsampled = pd.concat([not_fraud_downsampled, fraud])\n",
    "\n",
    "# checking counts\n",
    "downsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying logistic regression again with undersampled dataset\n",
    "\n",
    "y_train = downsampled.Class\n",
    "X_train = downsampled.drop('Class', axis=1)\n",
    "\n",
    "undersampled = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "\n",
    "undersampled_pred = undersampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9758574197354007"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking accuracy\n",
    "accuracy_score(y_test, undersampled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11710323574730355"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score\n",
    "f1_score(y_test, undersampled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69369</td>\n",
       "      <td>1701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1\n",
       "0  69369  1701\n",
       "1     18   114"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, undersampled_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8636363636363636"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall score\n",
    "recall_score(y_test, undersampled_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsampling produced a higher recall score than upsampling. However, it is of concern that the number of total samples used to train the model is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating synthetic samples\n",
    "# SMOTE - Synthetic Minority Oversampling Technique\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input features and target\n",
    "y = df.Class\n",
    "X = df.drop('Class', axis=1)\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n",
    "\n",
    "sm = SMOTE(random_state=27, sampling_strategy=1.0)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9858571388444145"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "\n",
    "smote_pred = smote.predict(X_test)\n",
    "\n",
    "# Checking accuracy\n",
    "accuracy_score(y_test, smote_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18461538461538463"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score\n",
    "f1_score(y_test, smote_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70081</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  70081  989\n",
       "1     18  114"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, smote_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8636363636363636"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, smote_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
